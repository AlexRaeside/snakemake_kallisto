
# read in yaml


configfile: "src/test.yaml"


##--- required modules ---------------------------------------------------------

import snakemake_modules.kallisto as kal
import snakemake_modules.metadata as meta
import pandas as pd


##--- required modules ---------------------------------------------------------




rule make_metadata_table:
    # generate a metadata csv file from either the list of fastq paths 
    # or a path to a directory with fastq or fastq.gz
    input:
        fq_files = config["fastq_R1"],
        fq_dir = config["fastq_dir"],
        out_dir = config["output_dir"]
    output:
        metadata = config["output_dir"] + "/metadata/metadata.csv"
    # if there were no fastq files given then get fastqs from fq_dir
    run:
        
        
        if len(input.fq_files) != 0:
            fq_paths = input.fq_files
        if len(input.fq_files) == 0:
            fq_paths =  meta.get_fastq_in_dir(input.fq_dir)
        meta.write_sample_metadata(fq_paths, input.out_dir)


rule kallisto_index:
    input:
        fasta = config["fasta"]
    output:
        index = config["output_dir"] + "/index/" + kal.get_indx_name(config["fasta"])
    shell:
        "kallisto index --index={output.index} {input.fasta}"
    
    
    
fastqc_dir = config["output_dir"] + "/fastqc"
metadata_path = config["output_dir"] + "/metadata/metadata.csv" 

def fastq_path(sample_name):
    
    # load in metadata 
    meta = pd.read_csv(config["output_dir"] + "/metadata/metadata.csv") 
    sample_info = meta[meta["sample_name"] == str(sample_name)]
    fastq = sample_info["fastqR1_file"].loc[sample_info.index[0]]
    return(fastq)


rule fastqc:
    input: 
        fq = fastq_path,
        metadata = metadata_path
    output:
        fastqc_report = fastqc_dir + "/{sample}_fastqc/fastqc_data.txt"
    run:
        if not os.path.exists(fastqc_dir):
            os.mkdir(fastqc_dir)
        shell("fastqc -o {fastqc_dir} --extract {input.fq}")


quant_dir = config["output_dir"] + "/quant"

def get_mean_len(sample_name):
    
    fastqc_report = fastqc_dir + "/" + str(sample_name) + "_fastqc/fastqc_data.txt"
    
    file = open(fastqc_report)
  
    # read the content of the file opened
    length_line =  file.readlines()[8]
    length = length_line.split()[2]
    return(length)



rule kallisto_quant:
    input:
        fq = fastq_path,
        index = config["output_dir"] + "/index/" + kal.get_indx_name(config["fasta"]),
        fastqc_report = fastqc_dir + "/{sample}_fastqc/fastqc_data.txt"
    output: 
        count_tbl = quant_dir + "/{sample}/abundance.tsv",
        count_summary = quant_dir + "/{sample}/run_info.json",
        quant_done = config["output_dir"] + "/done/quant_{sample}.txt"
    params: 
        thread = config["threads"],
        mean_len = get_mean_len,
        out_path = quant_dir + "/{sample}"
    run:
        if not os.path.exists(quant_dir):
            os.mkdir(quant_dir)
        # get average read length from fastqc report 
        shell(
            "kallisto quant -i {input.index} -o {params.out_path} --single -l {params.mean_len} -s 20  --single-overhang -t {params.thread} {input.fq}")
        shell(
            "touch {output.quant_done}"
        )


# this is weird beacuse it can work with any one of the sample wildcards
# this i need two functions that get me lists to expand on with all n abundance.tsv




rule create_test:
    input:
        samples = "test",
        count_tbl = quant_dir + "/{sample}/abundance.tsv",
        count_summary = quant_dir + "/{sample}/run_info.json"
    output:
        total_counts_tbl = config["output_dir"] +"/tables/counts_raw.csv",
        total_counts_summary = config["output_dir"] +"/tables/counts_summary.csv"
    run:
        
        if not os.path.exists(tables_dir):
            os.mkdir(tables_dir)
        
        kal.create_blank_tbls("{input.count_tbl}", tables_dir)

